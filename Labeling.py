# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CFW4GDKD8d28hHs0FDlMnVXNRGWI0r0v
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from sklearn.cluster import KMeans

# --- Paste your pipeline code here ---
# (Include load_data, detect_idle_levels, merge_short_states, and IdleLevelDetectionPipeline)
# Modify plot_idle_and_timeline to return figures instead of showing
def load_data(file_path):
    """Original load_data function - unchanged"""
    import pandas as pd

    try:
        # Use the actual column names here, for example:
        needed_cols = [ 'time', 'value']  # replace with your real column names

        data = pd.read_csv(file_path, usecols=needed_cols)

        # Combine or parse time columns as needed:
        # If 'time' column is already ISO datetime string (e.g., '2025-05-14T08:00:00.000Z'):
        data['datetime'] = pd.to_datetime(data['time'])

        # Rename 'value' to 'current'
        data = data.rename(columns={'value': 'current'})

        # Create timestamp (unix seconds)
        data['timestamp'] = data['datetime'].astype('int64') // 1_000_000_000

        # Reorder columns
        data = data[['timestamp', 'datetime', 'current']]

        return data

    except Exception as e:
        print(f"âŒ Error loading {file_path}: {e}")
        return None

def detect_idle_levels(data, current_col,
                       window_size,
                       std_threshold,
                       n_idle_levels,
                       stop_percentile,
                       mean_margin_ratio):  # â† Updated defaults
    """
    Detect idle levels in current data using flat regions and KMeans clustering.
    """
    # Step 1: Calculate thresholds
    overall_mean = data[current_col].max() / 2
    stop_threshold = data[current_col].quantile(stop_percentile / 100.0)
    upper_limit = overall_mean + mean_margin_ratio * overall_mean  # â† Wider margin
    # Step 2: Identify flat low-variation regions in the extended range
    rolling_std = data[current_col].rolling(window=window_size, center=True, min_periods=1).std()
    valid_range = (data[current_col] > stop_threshold) & (data[current_col] < upper_limit)
    flat_regions = (rolling_std < std_threshold) & valid_range
    # Step 3: Cluster the flat values
    flat_values = data.loc[flat_regions, current_col].values.reshape(-1, 1)
    if len(flat_values) == 0:
        print("No flat idle-level regions detected.")
        labels = pd.Series(['not_idle'] * len(data), index=data.index)
        return labels, np.array([])
    kmeans = KMeans(n_clusters=n_idle_levels, random_state=42).fit(flat_values)
    idle_levels = kmeans.cluster_centers_.flatten()
    idle_levels = np.sort(kmeans.cluster_centers_.flatten())

    # Merge levels closer than a certain threshold (e.g., 0.5A)
    merge_threshold = 2  # Adjust this as needed
    merged_levels = [idle_levels[0]]
    for level in idle_levels[1:]:
        if abs(level - merged_levels[-1]) < merge_threshold:
            merged_levels[-1] = (merged_levels[-1] + level) / 2  # Average the two
        else:
            merged_levels.append(level)

    idle_levels = np.array(merged_levels)

    # Step 4: Label the original data
    idle_mask = pd.Series(False, index=data.index)
    idle_mask.loc[flat_regions] = True  # lock in idle

    # Initialize all as 'not_idle'
    labels = pd.Series('not_idle', index=data.index)
    labels[idle_mask] = 'idle'  # first assign idle â€” do not touch again!

    # Now work only on the rest
    not_idle_mask = ~idle_mask

    # Define threshold for stop (e.g., 5th percentile)
    stop_threshold = data[current_col].quantile(stop_percentile / 100.0)

    # Classify remaining 'not_idle' points as stop or run
    stop_mask = (data[current_col] <= stop_threshold) & not_idle_mask 
    run_mask = not_idle_mask & ~stop_mask

    labels[stop_mask] = 'stop'
    labels[run_mask] = 'run'


    return labels, idle_levels



def merge_short_states(labels: pd.Series, min_duration_sec: int) -> pd.Series:
    labels = labels.copy()
    states = []
    start_idx = 0
    prev_label = labels.iloc[0]
    for i in range(1, len(labels)):
        if labels.iloc[i] != prev_label:
            states.append((prev_label, start_idx, i - 1))
            start_idx = i
            prev_label = labels.iloc[i]
    states.append((prev_label, start_idx, len(labels) - 1))
    for i, (state, start, end) in enumerate(states):
        duration = end - start + 1
        if duration < min_duration_sec:
            if i > 0:
                prev_state, p_start, p_end = states[i - 1]
                labels.iloc[start:end + 1] = prev_state
            elif i < len(states) - 1:
                next_state, n_start, n_end = states[i + 1]
                labels.iloc[start:end + 1] = next_state
    return labels



def plot_idle_and_timeline(data, current_col, labels):
    # ðŸ§  Ensure labels match the index of data
    labels = labels.reindex(data.index)

    time = data.index if isinstance(data.index, pd.DatetimeIndex) else np.arange(len(data))

    # Base plot: current signal in light gray line
    fig1 = go.Figure()
    fig1.add_trace(go.Scatter(
        x=time,
        y=data[current_col],
        mode='lines',
        line=dict(color='lightgray'),
        name='Signal'
    ))

    color_map = {'idle': 'orange', 'run': 'green', 'stop': 'red'}

    # Helper function to get consecutive segments for each state
    def get_segments(labels):
        segments = []
        start_idx = 0
        current_label = labels.iloc[0]
        for i in range(1, len(labels)):
            if labels.iloc[i] != current_label:
                segments.append((start_idx, i - 1, current_label))
                start_idx = i
                current_label = labels.iloc[i]
        # Append last segment
        segments.append((start_idx, len(labels) - 1, current_label))
        return segments

    segments = get_segments(labels.reset_index(drop=True))

    for start, end, state in segments:
        if state in color_map:
            fig1.add_trace(go.Scatter(
                x=time[start:end+1],
                y=data[current_col].iloc[start:end+1],
                mode='lines',
                line=dict(color=color_map[state], width=3),
                name=state.capitalize(),
                showlegend=True
            ))

    fig1.update_layout(
        title="Current with Idle, Run, and Stop States (lines)",
        yaxis_title="Current",
        showlegend=True,
        height=400
    )

    # Timeline plot stays the same as you have it
    fig2 = go.Figure()
    state_changes = labels != labels.shift(1)
    change_indices = labels.index[state_changes].tolist()
    change_indices.append(labels.index[-1])

    for i in range(len(change_indices)-1):
        start_idx = change_indices[i]
        end_idx = change_indices[i+1]
        state = labels.loc[start_idx]
        if isinstance(state, pd.Series):
            state = state.iloc[0]
        color = color_map.get(state, 'lightgray')
        fig2.add_trace(go.Scatter(
            x=[start_idx, end_idx],
            y=[1, 1],
            mode='lines',
            line=dict(color=color, width=20),
            showlegend=False,
            hoverinfo='skip'
        ))

    fig2.update_layout(
        title="Machine State Timeline",
        yaxis=dict(visible=False, range=[0.5, 1.5]),
        xaxis_title="Time",
        height=150,
        margin=dict(t=40, b=40)
    )

    return fig1, fig2


# Your IdleLevelDetectionPipeline class with run_pipeline modified to return summary + figures

class IdleLevelDetectionPipeline:
    def __init__(self, window_size=10, std_threshold=0.5, n_idle_levels=3, stop_percentile=10, mean_margin_ratio=0.4):
        self.window_size = window_size
        self.std_threshold = std_threshold
        self.n_idle_levels = n_idle_levels
        self.stop_percentile = stop_percentile
        self.mean_margin_ratio = mean_margin_ratio
        self.data = None
        self.labels = None
        self.idle_levels = None

    def run_pipeline(self, file_path):
        data = load_data(file_path)
        if data is None:
            return None, None, None
        data.set_index('datetime', inplace=True)
        self.data = data
        labels, idle_levels = detect_idle_levels(data, 'current', self.window_size,
                                             self.std_threshold, self.n_idle_levels,
                                             self.stop_percentile, self.mean_margin_ratio)
        labels = merge_short_states(labels, min_duration_sec=1)
        self.labels = labels
        self.idle_levels = idle_levels

        fig1, fig2 = plot_idle_and_timeline(data, 'current', labels)
        summary_df, idle_levels = self.get_summary_stats()

        return summary_df, idle_levels, fig1, fig2

    
    def get_summary_stats(self):
        if self.labels is None or self.data is None:
            return None
    
        counts = self.labels.value_counts()
        total_samples = len(self.labels)
    
        durations_sec = counts  # assuming 1 sample = 1 second
    
        avg_current = self.data.groupby(self.labels).current.mean()
    
        # Collect data for all detected states
        states = sorted(set(self.labels.unique()) | {'idle', 'run', 'stop'})
    
        rows = []
        for state in states:
            count = counts.get(state, 0)
            duration = durations_sec.get(state, 0)
            avg = avg_current.get(state, np.nan)
            rows.append({
                'State': state,
                'Samples Count': count,
                'Duration (sec)': duration,
                'Avg Current (A)': round(avg, 2) if not np.isnan(avg) else None
            })
    
        summary_df = pd.DataFrame(rows)
    
        # Add idle levels info separately as a dict or list
        idle_levels = self.idle_levels if self.idle_levels is not None else []
    
        return summary_df, idle_levels


# Streamlit app
st.title("Interactive Idle Level Detection")

uploaded_file = st.file_uploader("Upload your CSV file", type=["csv"])
if uploaded_file is not None:
    # Save uploaded file temporarily
    with open("temp_uploaded_file.csv", "wb") as f:
        f.write(uploaded_file.getbuffer())

    st.sidebar.header("Pipeline Parameters")
    window_size = st.sidebar.slider("Window Size", 5, 100, 10)
    std_threshold = st.sidebar.slider("STD Threshold", 0.0, 1.0, 0.5, 0.01)
    n_idle_levels = st.sidebar.slider("Number of Idle Levels", 1, 5, 3)
    stop_percentile = st.sidebar.slider("Stop Percentile", 0, 100, 10)
    mean_margin_ratio = st.sidebar.slider("Mean Margin Ratio", 0.0, 1.0, 0.4, 0.01)
    if st.button("Run Pipeline"):
        pipeline = IdleLevelDetectionPipeline(
            window_size=window_size,
            std_threshold=std_threshold,
            n_idle_levels=n_idle_levels,
            stop_percentile=stop_percentile,
            mean_margin_ratio=mean_margin_ratio
        )
        summary_df, idle_levels, fig1, fig2 = pipeline.run_pipeline("temp_uploaded_file.csv")

        if summary_df is None:
            st.error("Failed to load or process the data.")
        else:
            st.success("Pipeline completed!")

        # Show idle levels in a simple text
            if len(idle_levels) > 0:
                st.markdown(f"**Detected idle levels (amperes):** {', '.join(f'{lvl:.2f}' for lvl in idle_levels)}")
            else:
                st.markdown("**No idle levels detected.**")

            # Interactive table
            st.dataframe(summary_df.style.format({
                'Samples Count': '{:,}',
                'Duration (sec)': '{:,}',
                'Avg Current (A)': '{:.2f}'
            }))

            # Dropdown to select a state and show details
            selected_state = st.selectbox("Select state for details", summary_df['State'].tolist())

            state_info = summary_df[summary_df['State'] == selected_state].iloc[0]
            st.markdown(f"### Details for **{selected_state}** state:")
            st.markdown(f"- Samples Count: {state_info['Samples Count']:,}")
            st.markdown(f"- Duration (sec): {state_info['Duration (sec)']:,}")
            avg_cur = state_info['Avg Current (A)']
            st.markdown(f"- Average Current (A): {avg_cur:.2f}" if avg_cur is not None else "- Average Current (A): N/A")

            # Show plots
            st.plotly_chart(fig1)
            st.plotly_chart(fig2)

else:
    st.info("Please upload a CSV file to begin.")